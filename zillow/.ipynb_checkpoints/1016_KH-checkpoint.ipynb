{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Properties ...\n",
      "Loading Train ...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "os.getcwd()\n",
    "os.chdir('/home/ghk829/zillow')\n",
    "print('Loading Properties ...')\n",
    "properties2016 = pd.read_csv('./properties_2016.csv', low_memory = False)\n",
    "properties2017 = pd.read_csv('./properties_2017.csv', low_memory = False)\n",
    "\n",
    "print('Loading Train ...')\n",
    "train2016 = pd.read_csv('./train_2016_v2.csv', parse_dates=['transactiondate'], low_memory=False)\n",
    "train2017 = pd.read_csv('./train_2017.csv', parse_dates=['transactiondate'], low_memory=False)\n",
    "test_df = pd.read_csv('./sample_submission.csv', low_memory=False)\n",
    "properties = pd.read_csv('./properties_2016.csv', low_memory=False)\n",
    "# field is named differently in submission\n",
    "test_df['parcelid'] = test_df['ParcelId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_date_features(df):\n",
    "    df[\"transaction_year\"] = df[\"transactiondate\"].dt.year\n",
    "    df[\"transaction_month\"] = (df[\"transactiondate\"].dt.year - 2016)*12 + df[\"transactiondate\"].dt.month\n",
    "    df[\"transaction_day\"] = df[\"transactiondate\"].dt.day\n",
    "    df[\"transaction_quarter\"] = (df[\"transactiondate\"].dt.year - 2016)*4 +df[\"transactiondate\"].dt.quarter\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train2016 = add_date_features(train2016)\n",
    "train2017 = add_date_features(train2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge Train with Properties ...\n",
      "Tax Features 2017  ...\n",
      "Concat Train 2016 & 2017 ...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print('Merge Train with Properties ...')\n",
    "train2016 = pd.merge(train2016, properties2016, how = 'left', on = 'parcelid')\n",
    "train2017 = pd.merge(train2017, properties2017, how = 'left', on = 'parcelid')\n",
    "\n",
    "print('Tax Features 2017  ...')\n",
    "train2017.iloc[:, train2017.columns.str.startswith('tax')] = np.nan\n",
    "\n",
    "print('Concat Train 2016 & 2017 ...')\n",
    "train_df = pd.concat([train2016, train2017], axis = 0)\n",
    "test_df = pd.merge(test_df[['ParcelId']], properties2016.rename(columns = {'parcelid': 'ParcelId'}), how = 'left', on = 'ParcelId')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove missing data fields ...\n",
      "We exclude: 15\n"
     ]
    }
   ],
   "source": [
    "print('Remove missing data fields ...')\n",
    "\n",
    "missing_perc_thresh = 0.98\n",
    "exclude_missing = []\n",
    "num_rows = train_df.shape[0]\n",
    "for c in train_df.columns:\n",
    "    num_missing = train_df[c].isnull().sum()\n",
    "    if num_missing == 0:\n",
    "        continue\n",
    "    missing_frac = num_missing / float(num_rows)\n",
    "    if missing_frac > missing_perc_thresh:\n",
    "        exclude_missing.append(c)\n",
    "print(\"We exclude: %s\" % len(exclude_missing))\n",
    "\n",
    "del num_rows, missing_perc_thresh\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove features with one unique value !!\n",
      "We exclude: 9\n"
     ]
    }
   ],
   "source": [
    "print (\"Remove features with one unique value !!\")\n",
    "exclude_unique = []\n",
    "for c in train_df.columns:\n",
    "    num_uniques = len(train_df[c].unique())\n",
    "    if train_df[c].isnull().sum() != 0:\n",
    "        num_uniques -= 1\n",
    "    if num_uniques == 1:\n",
    "        exclude_unique.append(c)\n",
    "print(\"We exclude: %s\" % len(exclude_unique))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Define training features !!\n",
      "We use these for training: 43\n"
     ]
    }
   ],
   "source": [
    "print (\"Define training features !!\")\n",
    "exclude_other = ['parcelid', 'logerror','propertyzoningdesc']\n",
    "train_features = []\n",
    "for c in train_df.columns:\n",
    "    if c not in exclude_missing \\\n",
    "       and c not in exclude_other and c not in exclude_unique:\n",
    "        train_features.append(c)\n",
    "print(\"We use these for training: %s\" % len(train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing NaN values by 0 !!\n",
      "remove outliers\n",
      "0:finishedfloor1squarefeet\n",
      "1:garagetotalsqft\n",
      "2:lotsizesquarefeet\n",
      "3:poolsizesum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ghk829/miniconda2/lib/python2.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ghk829/miniconda2/lib/python2.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train: ', (74478, 68))\n",
      "('Test: ', (89999, 68))\n"
     ]
    }
   ],
   "source": [
    "print (\"Replacing NaN values by 0 !!\")\n",
    "train_df.fillna(0, inplace=True)\n",
    "test_df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "print (\"remove outliers\")\n",
    "train_df=train_df[ train_df.logerror > -0.4 ]\n",
    "train_df=train_df[ train_df.logerror < 0.419 ]\n",
    "\n",
    "train_df=train_df.assign(diff_cal_fin=lambda x: x.calculatedfinishedsquarefeet-x.finishedfloor1squarefeet)\n",
    "new_cols=['finishedfloor1squarefeet',\n",
    "'garagetotalsqft',\n",
    "'lotsizesquarefeet',\n",
    "'poolsizesum']\n",
    "for i,value in enumerate(new_cols):\n",
    "    print(str(i)+\":\"+value)\n",
    "    train_df=eval(\"train_df.assign(new_{}=lambda x: x.{} /x.calculatedfinishedsquarefeet)\".format(value,value))\n",
    "\n",
    "VAL_SPLIT_DATE = '2016-09-15'   # Cutoff date for validation split\n",
    "select_qtr4 = train_df[\"transactiondate\"] >= VAL_SPLIT_DATE\n",
    "valid = train_df[select_qtr4]\n",
    "train = train_df[~select_qtr4]\n",
    "valid.drop([\"transactiondate\"], inplace=True, axis=1)\n",
    "train.drop([\"transactiondate\"], inplace=True, axis=1)\n",
    "print(\"Train: \", train.shape)\n",
    "print(\"Test: \", valid.shape)\n",
    "\n",
    "test_df['transactiondate'] = pd.Timestamp('2016-12-01') \n",
    "test_df = add_date_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Define categorial features !!\n",
      "Cat features are: ['transaction_year', 'transaction_month', 'transaction_day', 'transaction_quarter', 'airconditioningtypeid', 'buildingqualitytypeid', 'fips', 'heatingorsystemtypeid', 'propertycountylandusecode', 'propertylandusetypeid', 'regionidcity', 'regionidcounty', 'regionidneighborhood', 'regionidzip', 'yearbuilt', 'assessmentyear']\n"
     ]
    }
   ],
   "source": [
    "train_features.remove('transactiondate')\n",
    "print (\"Define categorial features !!\")\n",
    "cat_feature_inds = []\n",
    "cat_unique_thresh = 1000\n",
    "for i, c in enumerate(train_features):\n",
    "    num_uniques = len(train_df[c].unique())\n",
    "    if num_uniques < cat_unique_thresh \\\n",
    "       and not 'sqft' in c \\\n",
    "       and not 'cnt' in c \\\n",
    "       and not 'nbr' in c \\\n",
    "       and not 'number' in c:\n",
    "        cat_feature_inds.append(i)\n",
    "        \n",
    "print(\"Cat features are: %s\" % [train_features[ind] for ind in cat_feature_inds])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features_new = train_features+['finishedfloor1squarefeet',\n",
    "'garagetotalsqft',\n",
    "'lotsizesquarefeet',\n",
    "'poolsizesum','diff_cal_fin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from tqdm import tqdm\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((74478, 47), (74478,))\n",
      "((89999, 47), (89999,))\n"
     ]
    }
   ],
   "source": [
    "X_train = train[train_features_new]\n",
    "y_train = train.logerror\n",
    "X_valid = valid[train_features_new]\n",
    "y_valid = valid.logerror\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_ensembles = 2\n",
    "tree_counts = []\n",
    "MAEs = []\n",
    "for i in range(num_ensembles):\n",
    "    # TODO(you): Use CV, tune hyperparameters\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=10, learning_rate=0.004,\n",
    "        depth=6, l2_leaf_reg=15,\n",
    "        bagging_temperature=8,\n",
    "        loss_function='MAE',\n",
    "        eval_metric='MAE',\n",
    "        random_seed=i)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[X_valid, y_valid],\n",
    "        cat_features=cat_feature_inds,\n",
    "#        verbose=True,\n",
    "        use_best_model=True\n",
    "        )\n",
    "    tree_counts.append( model.tree_count_ )\n",
    "    MAEs.append( mean_absolute_error(y_valid, model.predict(X_valid)) )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:finishedfloor1squarefeet\n",
      "1:garagetotalsqft\n",
      "2:lotsizesquarefeet\n",
      "3:poolsizesum\n"
     ]
    }
   ],
   "source": [
    "test_df=test_df.assign(diff_cal_fin=lambda x: x.calculatedfinishedsquarefeet-x.finishedfloor1squarefeet)\n",
    "new_cols=['finishedfloor1squarefeet',\n",
    "'garagetotalsqft',\n",
    "'lotsizesquarefeet',\n",
    "'poolsizesum']\n",
    "for i,value in enumerate(new_cols):\n",
    "    print(str(i)+\":\"+value)\n",
    "    test_df=eval(\"test_df.assign(new_{}=lambda x: x.{} /x.calculatedfinishedsquarefeet)\".format(value,value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test=test_df[train_features_new]\n",
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for: 201612 ... \n",
      "Predicting for: 201610 ... \n",
      "Predicting for: 201611 ... \n",
      "Predicting for: 201712 ... \n",
      "Predicting for: 201711 ... \n",
      "Predicting for: 201710 ... \n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'ParcelId': test_df['ParcelId'],\n",
    "})\n",
    "test_dates = {\n",
    "    '201610': pd.Timestamp('2016-10-01'),\n",
    "    '201611': pd.Timestamp('2016-11-01'),\n",
    "    '201612': pd.Timestamp('2016-12-01'),\n",
    "    '201710': pd.Timestamp('2017-10-01'),\n",
    "    '201711': pd.Timestamp('2017-11-01'),\n",
    "    '201712': pd.Timestamp('2017-12-02')\n",
    "}\n",
    "for label, test_date in test_dates.items():\n",
    "    print(\"Predicting for: %s ... \" % (label))\n",
    "    submission[label] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-1d9c77237750>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./final_solution_0.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%.6f'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ghk829/miniconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1401\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1403\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ghk829/miniconda2/lib/python2.7/site-packages/pandas/io/formats/format.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1590\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mwriter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ghk829/miniconda2/lib/python2.7/site-packages/pandas/io/formats/format.pyc\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1691\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1693\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1695\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ghk829/miniconda2/lib/python2.7/site-packages/pandas/io/formats/format.pyc\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m   1717\u001b[0m                                         quoting=self.quoting)\n\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1719\u001b[0;31m         \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_csv_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.write_csv_rows (pandas/_libs/lib.c:20130)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "submission.to_csv('./final_solution_0.csv', float_format='%.6f',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
