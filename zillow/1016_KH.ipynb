{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Properties ...\n",
      "Loading Train ...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn import neighbors\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('/home/ghk829/zillow')\n",
    "print('Loading Properties ...')\n",
    "properties2016 = pd.read_csv('./properties_2016.csv', low_memory = False)\n",
    "properties2017 = pd.read_csv('./properties_2017.csv', low_memory = False)\n",
    "\n",
    "print('Loading Train ...')\n",
    "train2016 = pd.read_csv('./train_2016_v2.csv', parse_dates=['transactiondate'], low_memory=False)\n",
    "train2017 = pd.read_csv('./train_2017.csv', parse_dates=['transactiondate'], low_memory=False)\n",
    "test_df = pd.read_csv('./sample_submission.csv', low_memory=False)\n",
    "properties = pd.read_csv('./properties_2016.csv', low_memory=False)\n",
    "# field is named differently in submission\n",
    "test_df['parcelid'] = test_df['ParcelId']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_date_features(df):\n",
    "    df[\"transaction_year\"] = df[\"transactiondate\"].dt.year\n",
    "    df[\"transaction_month\"] = (df[\"transactiondate\"].dt.year - 2016)*12 + df[\"transactiondate\"].dt.month\n",
    "    df[\"transaction_day\"] = df[\"transactiondate\"].dt.day\n",
    "    df[\"transaction_quarter\"] = (df[\"transactiondate\"].dt.year - 2016)*4 +df[\"transactiondate\"].dt.quarter\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fillna_knn( df, base, target, fraction = 1, threshold = 10, n_neighbors = 5 ):\n",
    "    assert isinstance( base , list ) or isinstance( base , np.ndarray ) and isinstance( target, str ) \n",
    "    whole = [ target ] + base\n",
    "    \n",
    "    miss = df[target].isnull()\n",
    "    notmiss = ~miss \n",
    "    nummiss = miss.sum()\n",
    "    \n",
    "    enc = OneHotEncoder()\n",
    "    X_target = df.loc[ notmiss, whole ].sample( frac = fraction )\n",
    "    \n",
    "    enc.fit( X_target[ target ].unique().reshape( (-1,1) ) )\n",
    "    \n",
    "    Y = enc.transform( X_target[ target ].values.reshape((-1,1)) ).toarray()\n",
    "    X = X_target[ base  ]\n",
    "    \n",
    "    print( 'fitting' )\n",
    "    n_neighbors = n_neighbors\n",
    "    clf = neighbors.KNeighborsClassifier( n_neighbors, weights = 'uniform' )\n",
    "    clf.fit( X, Y )\n",
    "    \n",
    "    print( 'the shape of active features: ' ,enc.active_features_.shape )\n",
    "    \n",
    "    print( 'predicting' )\n",
    "    Z = clf.predict(df.loc[miss, base])\n",
    "    \n",
    "    numunperdicted = Z[:,0].sum()\n",
    "    if numunperdicted / nummiss *100 < threshold :\n",
    "        print( 'writing result to df' )    \n",
    "        df.loc[ miss, target ]  = np.dot( Z , enc.active_features_ )\n",
    "        print( 'num of unperdictable data: ', numunperdicted )\n",
    "        return enc\n",
    "    else:\n",
    "        print( 'out of threshold: {}% > {}%'.format( numunperdicted / nummiss *100 , threshold ) )\n",
    "\n",
    "#function to deal with variables that are actually string/categories\n",
    "def zoningcode2int( df, target ):\n",
    "    storenull = df[ target ].isnull()\n",
    "    enc = LabelEncoder( )\n",
    "    df[ target ] = df[ target ].astype( str )\n",
    "\n",
    "    print('fit and transform')\n",
    "    df[ target ]= enc.fit_transform( df[ target ].values )\n",
    "    print( 'num of categories: ', enc.classes_.shape  )\n",
    "    df.loc[ storenull, target ] = np.nan\n",
    "    print('recover the nan value')\n",
    "    return enc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train2016 = add_date_features(train2016)\n",
    "train2017 = add_date_features(train2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge Train with Properties ...\n",
      "Tax Features 2017  ...\n",
      "Concat Train 2016 & 2017 ...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print('Merge Train with Properties ...')\n",
    "train2016 = pd.merge(train2016, properties2016, how = 'left', on = 'parcelid')\n",
    "train2017 = pd.merge(train2017, properties2017, how = 'left', on = 'parcelid')\n",
    "\n",
    "print('Tax Features 2017  ...')\n",
    "train2017.iloc[:, train2017.columns.str.startswith('tax')] = np.nan\n",
    "\n",
    "print('Concat Train 2016 & 2017 ...')\n",
    "train_df = pd.concat([train2016, train2017], axis = 0)\n",
    "test_df = pd.merge(test_df[['ParcelId']], properties2016.rename(columns = {'parcelid': 'ParcelId'}), how = 'left', on = 'ParcelId')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df[train_df.latitude.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting\n",
      "('the shape of active features: ', (12,))\n",
      "predicting\n",
      "writing result to df\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ghk829/miniconda2/lib/python2.7/site-packages/pandas/core/indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/home/ghk829/miniconda2/lib/python2.7/site-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('num of unperdictable data: ', 158.0)\n",
      "fit and transform"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ghk829/miniconda2/lib/python2.7/site-packages/ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('num of categories: ', (91,))\n",
      "recover the nan value\n",
      "fitting\n",
      "('the shape of active features: ', (58,))\n",
      "predicting\n",
      "writing result to df\n",
      "('num of unperdictable data: ', 0.0)\n",
      "fit and transform\n",
      "('num of categories: ', (2347,))\n",
      "recover the nan value\n",
      "fitting\n",
      "('the shape of active features: ', (1321,))\n",
      "predicting\n",
      "writing result to df\n",
      "('num of unperdictable data: ', 0.0)\n",
      "fitting\n",
      "('the shape of active features: ', (171,))\n",
      "predicting\n",
      "writing result to df\n",
      "('num of unperdictable data: ', 2.0)\n",
      "fitting\n",
      "('the shape of active features: ', (426,))\n",
      "predicting\n",
      "writing result to df\n",
      "('num of unperdictable data: ', 502.0)\n",
      "fitting\n",
      "('the shape of active features: ', (386,))\n",
      "predicting\n",
      "writing result to df\n",
      "('num of unperdictable data: ', 0.0)\n",
      "fitting\n",
      "('the shape of active features: ', (4,))\n",
      "predicting\n",
      "writing result to df\n",
      "('num of unperdictable data: ', 5559.0)\n",
      "fitting\n",
      "('the shape of active features: ', (129,))\n",
      "predicting\n",
      "writing result to df\n",
      "('num of unperdictable data: ', 0.0)\n",
      "fitting\n",
      "('the shape of active features: ', (10651,))\n",
      "predicting\n",
      "writing result to df\n",
      "('num of unperdictable data: ', 7.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<type 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fillna_knn( df = train_df,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'buildingqualitytypeid', fraction = 0.15, n_neighbors = 1 )\n",
    "\n",
    "\n",
    "zoningcode2int( df = train_df,\n",
    "                            target = 'propertycountylandusecode' )\n",
    "fillna_knn( df = train_df,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'propertycountylandusecode', fraction = 0.15, n_neighbors = 1 )\n",
    "\n",
    "zoningcode2int( df = train_df,\n",
    "                            target = 'propertyzoningdesc' )\n",
    "\n",
    "fillna_knn( df = train_df,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'propertyzoningdesc', fraction = 0.15, n_neighbors = 1 )\n",
    "\n",
    "#regionidcity, regionidneighborhood & regionidzip - assume it is the same as the nereast property. \n",
    "#As mentioned above, this is ok if there's a property very nearby to the one with missing values (I leave it up to the reader to check if this is the case!)\n",
    "fillna_knn( df = train_df,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'regionidcity', fraction = 0.15, n_neighbors = 1 )\n",
    "\n",
    "fillna_knn( df = train_df,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'regionidneighborhood', fraction = 0.15, n_neighbors = 1 )\n",
    "\n",
    "fillna_knn( df = train_df,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'regionidzip', fraction = 0.15, n_neighbors = 1 )\n",
    "\n",
    "#unitcnt - the number of structures the unit is built into. Assume it is the same as the nearest properties. If the property with missing values is in a block of flats or in a terrace street then this is probably ok - but again I leave it up to the reader to check if this is the case!\n",
    "fillna_knn( df = train_df,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'unitcnt', fraction = 0.15, n_neighbors = 1 )\n",
    "\n",
    "#yearbuilt - assume it is the same as the nearest property. This assumes properties all near to each other were built around the same time\n",
    "fillna_knn( df = train_df,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'yearbuilt', fraction = 0.15, n_neighbors = 1 )\n",
    "\n",
    "#lot size square feet - not sure what to do about this one. Lets use nearest neighbours. Assume it has same lot size as property closest to it\n",
    "fillna_knn( df = train_df,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'lotsizesquarefeet', fraction = 0.15, n_neighbors = 1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove features with one unique value !!\n",
      "We exclude: 9\n"
     ]
    }
   ],
   "source": [
    "print (\"Remove features with one unique value !!\")\n",
    "exclude_unique = []\n",
    "for c in train_df.columns:\n",
    "    num_uniques = len(train_df[c].unique())\n",
    "    if train_df[c].isnull().sum() != 0:\n",
    "        num_uniques -= 1\n",
    "    if num_uniques == 1:\n",
    "        exclude_unique.append(c)\n",
    "print(\"We exclude: %s\" % len(exclude_unique))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Define training features !!\n",
      "We use these for training: 43\n"
     ]
    }
   ],
   "source": [
    "print (\"Define training features !!\")\n",
    "exclude_other = ['parcelid', 'logerror','propertyzoningdesc']\n",
    "train_features = []\n",
    "for c in train_df.columns:\n",
    "    if c not in exclude_missing \\\n",
    "       and c not in exclude_other and c not in exclude_unique:\n",
    "        train_features.append(c)\n",
    "print(\"We use these for training: %s\" % len(train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing NaN values by 0 !!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ghk829/miniconda2/lib/python2.7/site-packages/pandas/core/frame.py:2754: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove outliers\n",
      "0:finishedfloor1squarefeet\n",
      "1:garagetotalsqft\n",
      "2:lotsizesquarefeet\n",
      "3:poolsizesum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ghk829/miniconda2/lib/python2.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ghk829/miniconda2/lib/python2.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train: ', (74478, 68))\n",
      "('Test: ', (89971, 68))\n"
     ]
    }
   ],
   "source": [
    "print (\"Replacing NaN values by 0 !!\")\n",
    "train_df.fillna(0, inplace=True)\n",
    "test_df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "print (\"remove outliers\")\n",
    "train_df=train_df[ train_df.logerror > -0.4 ]\n",
    "train_df=train_df[ train_df.logerror < 0.419 ]\n",
    "\n",
    "train_df=train_df.assign(diff_cal_fin=lambda x: x.calculatedfinishedsquarefeet-x.finishedfloor1squarefeet)\n",
    "new_cols=['finishedfloor1squarefeet',\n",
    "'garagetotalsqft',\n",
    "'lotsizesquarefeet',\n",
    "'poolsizesum']\n",
    "for i,value in enumerate(new_cols):\n",
    "    print(str(i)+\":\"+value)\n",
    "    train_df=eval(\"train_df.assign(new_{}=lambda x: x.{} /x.calculatedfinishedsquarefeet)\".format(value,value))\n",
    "\n",
    "VAL_SPLIT_DATE = '2016-09-15'   # Cutoff date for validation split\n",
    "select_qtr4 = train_df[\"transactiondate\"] >= VAL_SPLIT_DATE\n",
    "valid = train_df[select_qtr4]\n",
    "train = train_df[~select_qtr4]\n",
    "valid.drop([\"transactiondate\"], inplace=True, axis=1)\n",
    "train.drop([\"transactiondate\"], inplace=True, axis=1)\n",
    "print(\"Train: \", train.shape)\n",
    "print(\"Test: \", valid.shape)\n",
    "\n",
    "test_df['transactiondate'] = pd.Timestamp('2016-12-01') \n",
    "test_df = add_date_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Define categorial features !!\n",
      "Cat features are: ['transaction_year', 'transaction_month', 'transaction_day', 'transaction_quarter', 'airconditioningtypeid', 'buildingqualitytypeid', 'fips', 'heatingorsystemtypeid', 'propertycountylandusecode', 'propertylandusetypeid', 'regionidcity', 'regionidcounty', 'regionidneighborhood', 'regionidzip', 'yearbuilt', 'assessmentyear']\n"
     ]
    }
   ],
   "source": [
    "train_features.remove('transactiondate')\n",
    "print (\"Define categorial features !!\")\n",
    "cat_feature_inds = []\n",
    "cat_unique_thresh = 1000\n",
    "for i, c in enumerate(train_features):\n",
    "    num_uniques = len(train_df[c].unique())\n",
    "    if num_uniques < cat_unique_thresh \\\n",
    "       and not 'sqft' in c \\\n",
    "       and not 'cnt' in c \\\n",
    "       and not 'nbr' in c \\\n",
    "       and not 'number' in c:\n",
    "        cat_feature_inds.append(i)\n",
    "        \n",
    "print(\"Cat features are: %s\" % [train_features[ind] for ind in cat_feature_inds])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features_new = train_features+['new_finishedfloor1squarefeet',\n",
    "'new_garagetotalsqft',\n",
    "'new_lotsizesquarefeet',\n",
    "'new_poolsizesum','diff_cal_fin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((74478, 47), (74478,))\n",
      "((89971, 47), (89971,))\n"
     ]
    }
   ],
   "source": [
    "X_train = train[train_features_new]\n",
    "y_train = train.logerror\n",
    "X_valid = valid[train_features_new]\n",
    "y_valid = valid.logerror\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.052331489140260055, 0.052346852539937538, 0.052348389715953444]\n"
     ]
    }
   ],
   "source": [
    "num_ensembles = 3\n",
    "tree_counts = []\n",
    "MAEs = []\n",
    "for i in range(num_ensembles):\n",
    "    # TODO(you): Use CV, tune hyperparameters\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=200, learning_rate=0.004,\n",
    "        depth=6, l2_leaf_reg=15,\n",
    "        bagging_temperature=8,\n",
    "        loss_function='MAE',\n",
    "        eval_metric='MAE',\n",
    "        random_seed=i)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[X_valid, y_valid],\n",
    "        cat_features=cat_feature_inds,\n",
    "#        verbose=True,\n",
    "        use_best_model=True\n",
    "        )\n",
    "    tree_counts.append( model.tree_count_ )\n",
    "    MAEs.append( mean_absolute_error(y_valid, model.predict(X_valid)) )\n",
    "print(MAEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:finishedfloor1squarefeet\n",
      "1:garagetotalsqft\n",
      "2:lotsizesquarefeet\n",
      "3:poolsizesum\n"
     ]
    }
   ],
   "source": [
    "test_df=test_df.assign(diff_cal_fin=lambda x: x.calculatedfinishedsquarefeet-x.finishedfloor1squarefeet)\n",
    "new_cols=['finishedfloor1squarefeet',\n",
    "'garagetotalsqft',\n",
    "'lotsizesquarefeet',\n",
    "'poolsizesum']\n",
    "for i,value in enumerate(new_cols):\n",
    "    print(str(i)+\":\"+value)\n",
    "    test_df=eval(\"test_df.assign(new_{}=lambda x: x.{} /x.calculatedfinishedsquarefeet)\".format(value,value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test=test_df[train_features_new]\n",
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for: 201612 ... \n",
      "Predicting for: 201610 ... \n",
      "Predicting for: 201611 ... \n",
      "Predicting for: 201712 ... \n",
      "Predicting for: 201711 ... \n",
      "Predicting for: 201710 ... \n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'ParcelId': test_df['ParcelId'],\n",
    "})\n",
    "test_dates = {\n",
    "    '201610': pd.Timestamp('2016-10-01'),\n",
    "    '201611': pd.Timestamp('2016-11-01'),\n",
    "    '201612': pd.Timestamp('2016-12-01'),\n",
    "    '201710': pd.Timestamp('2017-10-01'),\n",
    "    '201711': pd.Timestamp('2017-11-01'),\n",
    "    '201712': pd.Timestamp('2017-12-02')\n",
    "}\n",
    "for label, test_date in test_dates.items():\n",
    "    print(\"Predicting for: %s ... \" % (label))\n",
    "    submission[label] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove missing data fields ...\n",
      "We exclude: 15\n",
      "fitting\n",
      "('the shape of active features: ', (6,))\n",
      "predicting\n",
      "writing result to df\n",
      "('num of unperdictable data: ', 221.0)\n",
      "fit and transform\n",
      "('num of categories: ', (78,))\n",
      "recover the nan value\n",
      "fitting\n",
      "('the shape of active features: ', (46,))\n",
      "predicting\n",
      "writing result to df\n",
      "('num of unperdictable data: ', 0.0)\n",
      "fit and transform\n",
      "('num of categories: ', (1997,))\n",
      "recover the nan value\n",
      "fitting\n",
      "('the shape of active features: ', (1075,))\n",
      "predicting\n",
      "writing result to df\n",
      "('num of unperdictable data: ', 0.0)\n",
      "fitting\n",
      "('the shape of active features: ', (170,))\n",
      "predicting\n",
      "writing result to df\n",
      "('num of unperdictable data: ', 2.0)\n",
      "fitting\n",
      "('the shape of active features: ', (380,))\n",
      "predicting\n",
      "writing result to df\n",
      "('num of unperdictable data: ', 222.0)\n",
      "fitting\n",
      "('the shape of active features: ', (378,))\n",
      "predicting\n",
      "writing result to df\n",
      "('num of unperdictable data: ', 0.0)\n",
      "fitting\n",
      "('the shape of active features: ', (4,))\n",
      "predicting\n",
      "out of threshold: 18.4512248606% > 10%\n",
      "fitting\n",
      "('the shape of active features: ', (124,))\n",
      "predicting\n",
      "writing result to df\n",
      "('num of unperdictable data: ', 0.0)\n",
      "fitting\n",
      "('the shape of active features: ', (7126,))\n",
      "predicting\n",
      "writing result to df\n",
      "('num of unperdictable data: ', 0.0)\n",
      "Remove features with one unique value !!\n",
      "We exclude: 12\n",
      "Define training features !!\n",
      "We use these for training: 41\n",
      "Replacing NaN values by 0 !!\n",
      "remove outliers\n",
      "0:finishedfloor1squarefeet\n",
      "1:garagetotalsqft\n",
      "2:lotsizesquarefeet\n",
      "3:poolsizesum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ghk829/miniconda2/lib/python2.7/site-packages/ipykernel_launcher.py:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ghk829/miniconda2/lib/python2.7/site-packages/ipykernel_launcher.py:105: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train: ', (74478, 68))\n",
      "('Test: ', (14050, 68))\n",
      "Define categorial features !!\n",
      "Cat features are: ['transaction_month', 'transaction_day', 'transaction_quarter', 'airconditioningtypeid', 'buildingqualitytypeid', 'fips', 'heatingorsystemtypeid', 'propertycountylandusecode', 'propertylandusetypeid', 'regionidcity', 'regionidcounty', 'regionidneighborhood', 'regionidzip', 'yearbuilt']\n",
      "['transaction_month', 'transaction_day', 'transaction_quarter', 'airconditioningtypeid', 'bathroomcnt', 'bedroomcnt', 'buildingqualitytypeid', 'calculatedbathnbr', 'finishedfloor1squarefeet', 'calculatedfinishedsquarefeet', 'finishedsquarefeet12', 'finishedsquarefeet15', 'finishedsquarefeet50', 'fips', 'fireplacecnt', 'fullbathcnt', 'garagecarcnt', 'garagetotalsqft', 'heatingorsystemtypeid', 'latitude', 'longitude', 'lotsizesquarefeet', 'propertycountylandusecode', 'propertylandusetypeid', 'rawcensustractandblock', 'regionidcity', 'regionidcounty', 'regionidneighborhood', 'regionidzip', 'roomcnt', 'threequarterbathnbr', 'unitcnt', 'yardbuildingsqft17', 'yearbuilt', 'numberofstories', 'structuretaxvaluedollarcnt', 'taxvaluedollarcnt', 'landtaxvaluedollarcnt', 'taxamount', 'censustractandblock', 'new_finishedfloor1squarefeet', 'new_garagetotalsqft', 'new_lotsizesquarefeet', 'new_poolsizesum', 'diff_cal_fin']\n",
      "((74478, 45), (74478,))\n",
      "((14050, 45), (14050,))\n"
     ]
    }
   ],
   "source": [
    "train_df=train2016\n",
    "print('Remove missing data fields ...')\n",
    "\n",
    "missing_perc_thresh = 0.98\n",
    "exclude_missing = []\n",
    "num_rows = train_df.shape[0]\n",
    "for c in train_df.columns:\n",
    "    num_missing = train_df[c].isnull().sum()\n",
    "    if num_missing == 0:\n",
    "        continue\n",
    "    missing_frac = num_missing / float(num_rows)\n",
    "    if missing_frac > missing_perc_thresh:\n",
    "        exclude_missing.append(c)\n",
    "print(\"We exclude: %s\" % len(exclude_missing))\n",
    "\n",
    "del num_rows, missing_perc_thresh\n",
    "gc.collect();\n",
    "train_df=train_df[train_df.latitude.notnull()]\n",
    "fillna_knn( df = train_df,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'buildingqualitytypeid', fraction = 0.15, n_neighbors = 1 )\n",
    "\n",
    "\n",
    "zoningcode2int( df = train_df,\n",
    "                            target = 'propertycountylandusecode' )\n",
    "fillna_knn( df = train_df,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'propertycountylandusecode', fraction = 0.15, n_neighbors = 1 )\n",
    "\n",
    "zoningcode2int( df = train_df,\n",
    "                            target = 'propertyzoningdesc' )\n",
    "\n",
    "fillna_knn( df = train_df,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'propertyzoningdesc', fraction = 0.15, n_neighbors = 1 )\n",
    "\n",
    "#regionidcity, regionidneighborhood & regionidzip - assume it is the same as the nereast property. \n",
    "#As mentioned above, this is ok if there's a property very nearby to the one with missing values (I leave it up to the reader to check if this is the case!)\n",
    "fillna_knn( df = train_df,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'regionidcity', fraction = 0.15, n_neighbors = 1 )\n",
    "\n",
    "fillna_knn( df = train_df,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'regionidneighborhood', fraction = 0.15, n_neighbors = 1 )\n",
    "\n",
    "fillna_knn( df = train_df,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'regionidzip', fraction = 0.15, n_neighbors = 1 )\n",
    "\n",
    "#unitcnt - the number of structures the unit is built into. Assume it is the same as the nearest properties. If the property with missing values is in a block of flats or in a terrace street then this is probably ok - but again I leave it up to the reader to check if this is the case!\n",
    "fillna_knn( df = train_df,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'unitcnt', fraction = 0.15, n_neighbors = 1 )\n",
    "\n",
    "#yearbuilt - assume it is the same as the nearest property. This assumes properties all near to each other were built around the same time\n",
    "fillna_knn( df = train_df,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'yearbuilt', fraction = 0.15, n_neighbors = 1 )\n",
    "\n",
    "#lot size square feet - not sure what to do about this one. Lets use nearest neighbours. Assume it has same lot size as property closest to it\n",
    "fillna_knn( df = train_df,\n",
    "                  base = [ 'latitude', 'longitude' ] ,\n",
    "                  target = 'lotsizesquarefeet', fraction = 0.15, n_neighbors = 1 )\n",
    "\n",
    "print (\"Remove features with one unique value !!\")\n",
    "exclude_unique = []\n",
    "for c in train_df.columns:\n",
    "    num_uniques = len(train_df[c].unique())\n",
    "    if train_df[c].isnull().sum() != 0:\n",
    "        num_uniques -= 1\n",
    "    if num_uniques == 1:\n",
    "        exclude_unique.append(c)\n",
    "print(\"We exclude: %s\" % len(exclude_unique))\n",
    "print (\"Define training features !!\")\n",
    "exclude_other = ['parcelid', 'logerror','propertyzoningdesc']\n",
    "train_features = []\n",
    "for c in train_df.columns:\n",
    "    if c not in exclude_missing \\\n",
    "       and c not in exclude_other and c not in exclude_unique:\n",
    "        train_features.append(c)\n",
    "print(\"We use these for training: %s\" % len(train_features))\n",
    "print (\"Replacing NaN values by 0 !!\")\n",
    "train_df.fillna(0, inplace=True)\n",
    "test_df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "print (\"remove outliers\")\n",
    "train_df=train_df[ train_df.logerror > -0.4 ]\n",
    "train_df=train_df[ train_df.logerror < 0.419 ]\n",
    "\n",
    "train_df=train_df.assign(diff_cal_fin=lambda x: x.calculatedfinishedsquarefeet-x.finishedfloor1squarefeet)\n",
    "new_cols=['finishedfloor1squarefeet',\n",
    "'garagetotalsqft',\n",
    "'lotsizesquarefeet',\n",
    "'poolsizesum']\n",
    "for i,value in enumerate(new_cols):\n",
    "    print(str(i)+\":\"+value)\n",
    "    train_df=eval(\"train_df.assign(new_{}=lambda x: x.{} /x.calculatedfinishedsquarefeet)\".format(value,value))\n",
    "\n",
    "VAL_SPLIT_DATE = '2016-09-15'   # Cutoff date for validation split\n",
    "select_qtr4 = train_df[\"transactiondate\"] >= VAL_SPLIT_DATE\n",
    "valid = train_df[select_qtr4]\n",
    "train = train_df[~select_qtr4]\n",
    "valid.drop([\"transactiondate\"], inplace=True, axis=1)\n",
    "train.drop([\"transactiondate\"], inplace=True, axis=1)\n",
    "print(\"Train: \", train.shape)\n",
    "print(\"Test: \", valid.shape)\n",
    "\n",
    "test_df['transactiondate'] = pd.Timestamp('2016-12-01') \n",
    "test_df = add_date_features(test_df)\n",
    "train_features.remove('transactiondate')\n",
    "print (\"Define categorial features !!\")\n",
    "cat_feature_inds = []\n",
    "cat_unique_thresh = 1000\n",
    "for i, c in enumerate(train_features):\n",
    "    num_uniques = len(train_df[c].unique())\n",
    "    if num_uniques < cat_unique_thresh \\\n",
    "       and not 'sqft' in c \\\n",
    "       and not 'cnt' in c \\\n",
    "       and not 'nbr' in c \\\n",
    "       and not 'number' in c:\n",
    "        cat_feature_inds.append(i)\n",
    "        \n",
    "print(\"Cat features are: %s\" % [train_features[ind] for ind in cat_feature_inds])\n",
    "train_features_new = train_features+['new_finishedfloor1squarefeet',\n",
    "'new_garagetotalsqft',\n",
    "'new_lotsizesquarefeet',\n",
    "'new_poolsizesum','diff_cal_fin']\n",
    "print train_features_new\n",
    "X_train = train[train_features_new]\n",
    "y_train = train.logerror\n",
    "X_valid = valid[train_features_new]\n",
    "y_valid = valid.logerror\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.051815088623889873, 0.051819626203590659, 0.051794808012161873]\n"
     ]
    }
   ],
   "source": [
    "num_ensembles = 3\n",
    "tree_counts = []\n",
    "MAEs = []\n",
    "for i in range(num_ensembles):\n",
    "    # TODO(you): Use CV, tune hyperparameters\n",
    "    model2 = CatBoostRegressor(\n",
    "        iterations=200, learning_rate=0.004,\n",
    "        depth=6, l2_leaf_reg=15,\n",
    "        bagging_temperature=8,\n",
    "        loss_function='MAE',\n",
    "        eval_metric='MAE',\n",
    "        random_seed=i)\n",
    "    model2.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[X_valid, y_valid],\n",
    "        cat_features=cat_feature_inds,\n",
    "#        verbose=True,\n",
    "        use_best_model=True\n",
    "        )\n",
    "    tree_counts.append( model2.tree_count_ )\n",
    "    MAEs.append( mean_absolute_error(y_valid, model2.predict(X_valid)) )\n",
    "print(MAEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:finishedfloor1squarefeet\n",
      "1:garagetotalsqft\n",
      "2:lotsizesquarefeet\n",
      "3:poolsizesum\n"
     ]
    }
   ],
   "source": [
    "test_df=test_df.assign(diff_cal_fin=lambda x: x.calculatedfinishedsquarefeet-x.finishedfloor1squarefeet)\n",
    "new_cols=['finishedfloor1squarefeet',\n",
    "'garagetotalsqft',\n",
    "'lotsizesquarefeet',\n",
    "'poolsizesum']\n",
    "for i,value in enumerate(new_cols):\n",
    "    print(str(i)+\":\"+value)\n",
    "    test_df=eval(\"test_df.assign(new_{}=lambda x: x.{} /x.calculatedfinishedsquarefeet)\".format(value,value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test=test_df[train_features_new]\n",
    "y_pred=model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for: 201612 ... \n",
      "Predicting for: 201610 ... \n",
      "Predicting for: 201611 ... \n"
     ]
    }
   ],
   "source": [
    "test_dates = {\n",
    "    '201610': pd.Timestamp('2016-10-01'),\n",
    "    '201611': pd.Timestamp('2016-11-01'),\n",
    "    '201612': pd.Timestamp('2016-12-01')\n",
    "}\n",
    "for label, test_date in test_dates.items():\n",
    "    print(\"Predicting for: %s ... \" % (label))\n",
    "    submission[label] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('./final_solution_0.csv', float_format='%.6f',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ghk829/zillow'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'parcelid', u'logerror', u'transactiondate', u'transaction_year',\n",
       "       u'transaction_month', u'transaction_day', u'transaction_quarter',\n",
       "       u'airconditioningtypeid', u'architecturalstyletypeid', u'basementsqft',\n",
       "       u'bathroomcnt', u'bedroomcnt', u'buildingclasstypeid',\n",
       "       u'buildingqualitytypeid', u'calculatedbathnbr', u'decktypeid',\n",
       "       u'finishedfloor1squarefeet', u'calculatedfinishedsquarefeet',\n",
       "       u'finishedsquarefeet12', u'finishedsquarefeet13',\n",
       "       u'finishedsquarefeet15', u'finishedsquarefeet50',\n",
       "       u'finishedsquarefeet6', u'fips', u'fireplacecnt', u'fullbathcnt',\n",
       "       u'garagecarcnt', u'garagetotalsqft', u'hashottuborspa',\n",
       "       u'heatingorsystemtypeid', u'latitude', u'longitude',\n",
       "       u'lotsizesquarefeet', u'poolcnt', u'poolsizesum', u'pooltypeid10',\n",
       "       u'pooltypeid2', u'pooltypeid7', u'propertycountylandusecode',\n",
       "       u'propertylandusetypeid', u'propertyzoningdesc',\n",
       "       u'rawcensustractandblock', u'regionidcity', u'regionidcounty',\n",
       "       u'regionidneighborhood', u'regionidzip', u'roomcnt', u'storytypeid',\n",
       "       u'threequarterbathnbr', u'typeconstructiontypeid', u'unitcnt',\n",
       "       u'yardbuildingsqft17', u'yardbuildingsqft26', u'yearbuilt',\n",
       "       u'numberofstories', u'fireplaceflag', u'structuretaxvaluedollarcnt',\n",
       "       u'taxvaluedollarcnt', u'assessmentyear', u'landtaxvaluedollarcnt',\n",
       "       u'taxamount', u'taxdelinquencyflag', u'taxdelinquencyyear',\n",
       "       u'censustractandblock', u'diff_cal_fin',\n",
       "       u'new_finishedfloor1squarefeet', u'new_garagetotalsqft',\n",
       "       u'new_lotsizesquarefeet', u'new_poolsizesum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
